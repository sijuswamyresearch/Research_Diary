---
title: "Review of Literature in Core Research Area - February 25, 2025"
author: "Siju Swamy"
date: "25 February,2025"
format: html
---

# Uncertainty-Driven Loss for Single Image Super-Resolution

## Research Gap Identified in the Paper

The authors argued that traditional Mean Squared Error (MSE) or L1 loss functions used in DL based super resolution models treat every pixel equally, regardless of its importance to visual perception. This is problematic because texture and edge areas carry more vital visual information than smooth areas, and MSE/L1 don't account for this spatial variation. The equal weightage is non-optimal because it does not adaptive to the local image features which is an open research problem.
Existing deep learning-based Single Image Super-Resolution (SISR) methods primarily focus on increasing network depth and complexity, or introducing attention mechanisms, while still relying on MSE or L1 loss. The authors contend that these methods do not explicitly address how to prioritize pixels containing important visual information in a principled and adaptive manner during the training process.

## Proposed Approach

In the context of SISR, authors coined a new term "uncertainty" refers to the inherent ambiguity in reconstructing a high-resolution (HR) image from a low-resolution (LR) counterpart. They used uncertainty as a measure of difficulty in accurate image reconstruction. 

The authors propose an *adaptive weighted loss*, uncertainty driven loss (UDL), that prioritizes texture and edge pixels with high uncertainty during training. Unlike traditional methods, UDL assigns larger weights to these pixels, forcing the network to focus on accurately reconstructing them. This addresses the limitations of MSE/L1 by explicitly accounting for the spatial variation in importance across different image regions.

There are two classes of uncertainty in Bayesian modeling: aleatoric uncertainty capturing noise inherent in observation data and epistemic uncertainty accounting for uncertainty of model about its predictions. The authors formulated SISR as a Bayesian estimation problem using the aleatoric uncertainty where the goal is to estimate not only the Super Resolved (SR) image (mean) but also its uncertainty (variance) simultaneously. This approach allows them to model the aleatoric uncertainty inherent in the SR process and to leverage prior knowledge for regularization.

Let $y_i$ and $x_i$ denote the low resolution and the respective high resolution image respectively. If $f(\cdot)$ denotes an arbitrary SISR network and aleatoric uncertainty $\theta_i$. The additive form of overall observation model can be written as:

$$
x_i = f(y_i) + \theta_i 
$${#eq-observation_model}

where $\epsilon$ represents the Laplace distribution with zero mean and unit variance.

Traditional DL based models just focused on the mean, $f(y_i)$ and discard the variance term $\theta_i$. For high level vision task it will not raise any issues. But this approach is not suitable for low-level vision tasks like SISR, where high-uncertainty pixels (e.g., texture and edge pixels) are visually more important and should be prioritized. This discrepancy motivates their approach of prioritizing pixels in low-level vision tasks.

For the $(x_i,y_i)$ pair, the likelihood function is defined as:

$$
p(x_i,\theta_i|y_i)=\dfrac{1}{2\theta_i}\text{exp}\left(-\dfrac{||x_i-f(y_i)||_1}{\theta_i}\right) 
$${#eq-eq2}

Where $f(y_i)$ and $\theta_i$ denote the SR image and the uncertainty which are to be learned by a DL network respectively.

The log-likelihood function is written as:

$$
\ln(p(x_i,\theta_i|y_i))=-\dfrac{||x_i-f(y_i)||_1}{\theta_i}-\ln(\theta_i)-\ln 2 
$${#eq-loglikeli}

To address the numerical stability of the estimation $s=-\ln (\theta_1)$ will be estimated from the log-likelihood of $N$ samples defined by:

$$
\mathcal{L}_{EU}=\frac{1}{N}\sum\limits_{i=1}^N\text{exp}(-s_i)||x_i-f(y_i)||_1+s_i 
$${#eq-log}

So a MLE of @eq-loglikeli is same as the minimization of @eq-log. $\mathcal{L}_{EU}$ is called the estimating uncertainty loss for the SR problem.

The authors observe that most pixels in an image have relatively low uncertainty, while only a few texture and edge pixels have high uncertainty. By imposing a sparsity prior, they prevent the network from predicting high uncertainty for all pixels, leading to a more accurate and meaningful uncertainty estimation.
The Jeffrey's prior, $p(\theta_i)\propto \dfrac{1}{\theta_i}$ is used to encourage sparsity in the uncertainty map.
Using the Bayer's probability:

$$
p(x_i,\theta_i|y_i)=p(x_i|y_i,\theta_i)\cdot p(\theta_i)=\dfrac{1}{2\theta_i}\text{exp}\left(-\dfrac{||x_i-f(y_i)||_1}{\theta_i}\right)\cdot \frac{1}{\theta_i}=\dfrac{1}{2\theta_i^2}\text{exp}\left(-\dfrac{||x_i-f(y_i)||_1}{\theta_i}\right) 
$$ {#eq-bayes}

The maximum likelihood estimate for logarithm of $\theta_i=s$ is the minimization of log likelihood of the joint distribution of @eq-bayes on $N$ samples.

Authors proposed this function as their new loss function as:

$$
\mathcal{L}_{ESU}=\frac{1}{N}\sum\limits_{i=1}^N\text{exp}(-s_i)||x_i-f(y_i)||_1+2s_i 
$$ {#eq-ESU}

To ensure stable performance in both high-level and low-lvel image processing applications, the authors proposed an adaptive loss function defined by:

$$
\mathcal{L}_{UDL}=\frac{1}{N}\sum\limits_{i=1}^N\\hat{s_i}||x_i-f(y_i)||_1
$${#eq-UDL}

Where $\hat{s_i}=s_i-\min{s_i}$; $i=1,\ldots , N$ is a non-negative linear scaling function.

To prevent uncertainty value from degenerating into zeros, the result of uncertainty estimation network in the first step will be  passed to the second step as the attention signal ($s =\ln(\theta)$). The two step flow diagram of the proposed UDL is shown in  @fig-fig1.

![](UDL-block.jpg){#fig-fig1}

## Two main components of the UDL

1. **Estimating Sparsity Uncertainty (ESU):** This component estimates the pixel-wise uncertainty (variance) of the SR image. They use a Convolutional Neural Network (CNN) to predict the log variance, and regularize it using Jeffrey's prior to promote sparsity in the uncertainty map. The loss used for this step is LESU.

2. **Uncertainty-Driven Loss (LUDL):** This is the adaptive weighted loss that guides the SISR network. It uses the uncertainty map estimated by ESU to assign larger weights to high-uncertainty pixels, effectively prioritizing them during training. The loss is computed using (@eq-UDL).

The method estimates a pixel-wise variance map (uncertainty) along with the SR image. It is assumed that the laplace distribution charateristics, can be captured with the variance map which is a latent variable. The authors use Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) to evaluate the performance of their proposed method. The experimental results demonstrate that the proposed UDL consistently outperforms traditional loss functions (MSE, L1) and other state-of-the-art SISR methods (including those that model uncertainty, like GRAM) in terms of PSNR and SSIM on several benchmark datasets.

## Key contributions of this work

The main contribution of the loss function based approach are:

1. A Bayesian estimation framework for SISR that simultaneously estimates the SR image and its uncertainty.

2. A new uncertainty-driven loss (UDL) that prioritizes high-uncertainty pixels during training.

3. A demonstration that UDL achieves better performance than traditional loss functions and other state-of-the-art methods without increasing computational cost during testing.


## Limitations of the Study

1. The authors did not provide a thorough analysis of the computational cost during the training phase, focusing primarily on the testing phase.

2. The method relies on a two-step training process, which may be more complex to implement and tune than single-step training methods.

3. The performance improvements, while consistent, are relatively modest in some cases.

4. The choice of Jeffrey's prior for regularizing the uncertainty map is somewhat heuristic and may not be optimal for all types of images.

## Future Work

1. The authors suggested exploring a deep equilibrium model for SISR by iteratively alternating between estimating the uncertainty (variance) and the mean value.

2. Investigate alternative priors for regularizing the uncertainty map.

3. Explore different network architectures for estimating uncertainty.

4. Develop end-to-end trainable UDL methods that do not require a two-step training process.

5. Apply the UDL framework to other low-level vision tasks.

6. Explore perceptual metrics in the loss function.

## Review Summary

Single image super-resolution (SISR) aims to reconstruct high-resolution (HR) images from their low-resolution (LR) counterparts. Traditional loss functions, such as Mean Squared Error (MSE) or L1 loss, treat all pixels equally, disregarding the varying importance of textures and edges. Existing SISR methods often fail to adequately address this, motivating the need for spatially adaptive approaches @ning2021uncertainty.

To overcome these limitations, authors proposed an uncertainty-driven loss (UDL) for SISR, prioritizing pixels with high uncertainty (e.g., textures and edges) during training. By casting SISR as a Bayesian estimation problem, their method simultaneously estimates the SR image (mean) and its uncertainty (variance). UDL incorporates an Estimating Sparsity Uncertainty (ESU) component regularized with Jeffrey's prior, ensuring a more accurate uncertainty map. This map then guides the uncertainty-driven loss itself (LUDL), weighting high-uncertainty pixels more heavily.

Experimental results demonstrated that the proposed UDL outperforms traditional loss functions and other SISR methods, achieving better Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) scores. Visual comparisons confirmed improved reconstruction of textures and edges. While promising, the authors note limitations regarding computational complexity during training and potential dataset biases. This work highlights the benefits of modeling uncertainty in SISR and provides a pathway for future research into adaptive loss functions for low-level vision tasks.

> Ning, Q., Dong, W., Li, X., Wu, J., & Shi, G. (2021). Uncertainty-Driven Loss for Single Image Super-Resolution. *35th Conference on Neural Information Processing Systems (NeurIPS 2021)*