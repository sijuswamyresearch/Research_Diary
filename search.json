[
  {
    "objectID": "PhD_Literature_survey.html",
    "href": "PhD_Literature_survey.html",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "The authors argued that traditional Mean Squared Error (MSE) or L1 loss functions used in DL based super resolution models treat every pixel equally, regardless of its importance to visual perception. This is problematic because texture and edge areas carry more vital visual information than smooth areas, and MSE/L1 don’t account for this spatial variation. The equal weightage is non-optimal because it does not adaptive to the local image features which is an open research problem. Existing deep learning-based Single Image Super-Resolution (SISR) methods primarily focus on increasing network depth and complexity, or introducing attention mechanisms, while still relying on MSE or L1 loss. The authors contend that these methods do not explicitly address how to prioritize pixels containing important visual information in a principled and adaptive manner during the training process.\n\n\n\nIn the context of SISR, authors coined a new term “uncertainty” refers to the inherent ambiguity in reconstructing a high-resolution (HR) image from a low-resolution (LR) counterpart. They used uncertainty as a measure of difficulty in accurate image reconstruction.\nThe authors propose an adaptive weighted loss, uncertainty driven loss (UDL), that prioritizes texture and edge pixels with high uncertainty during training. Unlike traditional methods, UDL assigns larger weights to these pixels, forcing the network to focus on accurately reconstructing them. This addresses the limitations of MSE/L1 by explicitly accounting for the spatial variation in importance across different image regions.\nThere are two classes of uncertainty in Bayesian modeling: aleatoric uncertainty capturing noise inherent in observation data and epistemic uncertainty accounting for uncertainty of model about its predictions. The authors formulated SISR as a Bayesian estimation problem using the aleatoric uncertainty where the goal is to estimate not only the Super Resolved (SR) image (mean) but also its uncertainty (variance) simultaneously. This approach allows them to model the aleatoric uncertainty inherent in the SR process and to leverage prior knowledge for regularization.\nLet \\(y_i\\) and \\(x_i\\) denote the low resolution and the respective high resolution image respectively. If \\(f(\\cdot)\\) denotes an arbitrary SISR network and aleatoric uncertainty \\(\\theta_i\\). The additive form of overall observation model can be written as:\n\\[\nx_i = f(y_i) + \\theta_i\n\\tag{1}\\]\nwhere \\(\\epsilon\\) represents the Laplace distribution with zero mean and unit variance.\nTraditional DL based models just focused on the mean, \\(f(y_i)\\) and discard the variance term \\(\\theta_i\\). For high level vision task it will not raise any issues. But this approach is not suitable for low-level vision tasks like SISR, where high-uncertainty pixels (e.g., texture and edge pixels) are visually more important and should be prioritized. This discrepancy motivates their approach of prioritizing pixels in low-level vision tasks.\nFor the \\((x_i,y_i)\\) pair, the likelihood function is defined as:\n\\[\np(x_i,\\theta_i|y_i)=\\dfrac{1}{2\\theta_i}\\text{exp}\\left(-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}\\right)\n\\tag{2}\\]\nWhere \\(f(y_i)\\) and \\(\\theta_i\\) denote the SR image and the uncertainty which are to be learned by a DL network respectively.\nThe log-likelihood function is written as:\n\\[\n\\ln(p(x_i,\\theta_i|y_i))=-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}-\\ln(\\theta_i)-\\ln 2\n\\tag{3}\\]\nTo address the numerical stability of the estimation \\(s=-\\ln (\\theta_1)\\) will be estimated from the log-likelihood of \\(N\\) samples defined by:\n\\[\n\\mathcal{L}_{EU}=\\frac{1}{N}\\sum\\limits_{i=1}^N\\text{exp}(-s_i)||x_i-f(y_i)||_1+s_i\n\\tag{4}\\]\nSo a MLE of Equation 3 is same as the minimization of Equation 4. \\(\\mathcal{L}_{EU}\\) is called the estimating uncertainty loss for the SR problem.\nThe authors observe that most pixels in an image have relatively low uncertainty, while only a few texture and edge pixels have high uncertainty. By imposing a sparsity prior, they prevent the network from predicting high uncertainty for all pixels, leading to a more accurate and meaningful uncertainty estimation. The Jeffrey’s prior, \\(p(\\theta_i)\\propto \\dfrac{1}{\\theta_i}\\) is used to encourage sparsity in the uncertainty map. Using the Bayer’s probability:\n\\[\np(x_i,\\theta_i|y_i)=p(x_i|y_i,\\theta_i)\\cdot p(\\theta_i)=\\dfrac{1}{2\\theta_i}\\text{exp}\\left(-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}\\right)\\cdot \\frac{1}{\\theta_i}=\\dfrac{1}{2\\theta_i^2}\\text{exp}\\left(-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}\\right)\n\\tag{5}\\]\nThe maximum likelihood estimate for logarithm of \\(\\theta_i=s\\) is the minimization of log likelihood of the joint distribution of Equation 5 on \\(N\\) samples.\nAuthors proposed this function as their new loss function as:\n\\[\n\\mathcal{L}_{ESU}=\\frac{1}{N}\\sum\\limits_{i=1}^N\\text{exp}(-s_i)||x_i-f(y_i)||_1+2s_i\n\\tag{6}\\]\nTo ensure stable performance in both high-level and low-lvel image processing applications, the authors proposed an adaptive loss function defined by:\n\\[\n\\mathcal{L}_{UDL}=\\frac{1}{N}\\sum\\limits_{i=1}^N\\\\hat{s_i}||x_i-f(y_i)||_1\n\\tag{7}\\]\nWhere \\(\\hat{s_i}=s_i-\\min{s_i}\\); \\(i=1,\\ldots , N\\) is a non-negative linear scaling function.\nTo prevent uncertainty value from degenerating into zeros, the result of uncertainty estimation network in the first step will be passed to the second step as the attention signal (\\(s =\\ln(\\theta)\\)). The two step flow diagram of the proposed UDL is shown in Figure 1.\n\n\n\n\n\n\nFigure 1: Block diagram of UDL implementation\n\n\n\n\n\n\n\nEstimating Sparsity Uncertainty (ESU): This component estimates the pixel-wise uncertainty (variance) of the SR image. They use a Convolutional Neural Network (CNN) to predict the log variance, and regularize it using Jeffrey’s prior to promote sparsity in the uncertainty map. The loss used for this step is LESU.\nUncertainty-Driven Loss (LUDL): This is the adaptive weighted loss that guides the SISR network. It uses the uncertainty map estimated by ESU to assign larger weights to high-uncertainty pixels, effectively prioritizing them during training. The loss is computed using (Equation 7).\n\nThe method estimates a pixel-wise variance map (uncertainty) along with the SR image. It is assumed that the laplace distribution charateristics, can be captured with the variance map which is a latent variable. The authors use Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) to evaluate the performance of their proposed method. The experimental results demonstrate that the proposed UDL consistently outperforms traditional loss functions (MSE, L1) and other state-of-the-art SISR methods (including those that model uncertainty, like GRAM) in terms of PSNR and SSIM on several benchmark datasets.\n\n\n\nThe main contribution of the loss function based approach are:\n\nA Bayesian estimation framework for SISR that simultaneously estimates the SR image and its uncertainty.\nA new uncertainty-driven loss (UDL) that prioritizes high-uncertainty pixels during training.\nA demonstration that UDL achieves better performance than traditional loss functions and other state-of-the-art methods without increasing computational cost during testing.\n\n\n\n\n\nThe authors did not provide a thorough analysis of the computational cost during the training phase, focusing primarily on the testing phase.\nThe method relies on a two-step training process, which may be more complex to implement and tune than single-step training methods.\nThe performance improvements, while consistent, are relatively modest in some cases.\nThe choice of Jeffrey’s prior for regularizing the uncertainty map is somewhat heuristic and may not be optimal for all types of images.\n\n\n\n\n\nThe authors suggested exploring a deep equilibrium model for SISR by iteratively alternating between estimating the uncertainty (variance) and the mean value.\nInvestigate alternative priors for regularizing the uncertainty map.\nExplore different network architectures for estimating uncertainty.\nDevelop end-to-end trainable UDL methods that do not require a two-step training process.\nApply the UDL framework to other low-level vision tasks.\nExplore perceptual metrics in the loss function.\n\n\n\n\nSingle image super-resolution (SISR) aims to reconstruct high-resolution (HR) images from their low-resolution (LR) counterparts. Traditional loss functions, such as Mean Squared Error (MSE) or L1 loss, treat all pixels equally, disregarding the varying importance of textures and edges. Existing SISR methods often fail to adequately address this, motivating the need for spatially adaptive approaches Ning et al. (2021).\nTo overcome these limitations, authors proposed an uncertainty-driven loss (UDL) for SISR, prioritizing pixels with high uncertainty (e.g., textures and edges) during training. By casting SISR as a Bayesian estimation problem, their method simultaneously estimates the SR image (mean) and its uncertainty (variance). UDL incorporates an Estimating Sparsity Uncertainty (ESU) component regularized with Jeffrey’s prior, ensuring a more accurate uncertainty map. This map then guides the uncertainty-driven loss itself (LUDL), weighting high-uncertainty pixels more heavily.\nExperimental results demonstrated that the proposed UDL outperforms traditional loss functions and other SISR methods, achieving better Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) scores. Visual comparisons confirmed improved reconstruction of textures and edges. While promising, the authors note limitations regarding computational complexity during training and potential dataset biases. This work highlights the benefits of modeling uncertainty in SISR and provides a pathway for future research into adaptive loss functions for low-level vision tasks.\n\nNing, Q., Dong, W., Li, X., Wu, J., & Shi, G. (2021). Uncertainty-Driven Loss for Single Image Super-Resolution. 35th Conference on Neural Information Processing Systems (NeurIPS 2021)"
  },
  {
    "objectID": "PhD_Literature_survey.html#research-gap-identified-in-the-paper",
    "href": "PhD_Literature_survey.html#research-gap-identified-in-the-paper",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "The authors argued that traditional Mean Squared Error (MSE) or L1 loss functions used in DL based super resolution models treat every pixel equally, regardless of its importance to visual perception. This is problematic because texture and edge areas carry more vital visual information than smooth areas, and MSE/L1 don’t account for this spatial variation. The equal weightage is non-optimal because it does not adaptive to the local image features which is an open research problem. Existing deep learning-based Single Image Super-Resolution (SISR) methods primarily focus on increasing network depth and complexity, or introducing attention mechanisms, while still relying on MSE or L1 loss. The authors contend that these methods do not explicitly address how to prioritize pixels containing important visual information in a principled and adaptive manner during the training process."
  },
  {
    "objectID": "PhD_Literature_survey.html#proposed-approach",
    "href": "PhD_Literature_survey.html#proposed-approach",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "In the context of SISR, authors coined a new term “uncertainty” refers to the inherent ambiguity in reconstructing a high-resolution (HR) image from a low-resolution (LR) counterpart. They used uncertainty as a measure of difficulty in accurate image reconstruction.\nThe authors propose an adaptive weighted loss, uncertainty driven loss (UDL), that prioritizes texture and edge pixels with high uncertainty during training. Unlike traditional methods, UDL assigns larger weights to these pixels, forcing the network to focus on accurately reconstructing them. This addresses the limitations of MSE/L1 by explicitly accounting for the spatial variation in importance across different image regions.\nThere are two classes of uncertainty in Bayesian modeling: aleatoric uncertainty capturing noise inherent in observation data and epistemic uncertainty accounting for uncertainty of model about its predictions. The authors formulated SISR as a Bayesian estimation problem using the aleatoric uncertainty where the goal is to estimate not only the Super Resolved (SR) image (mean) but also its uncertainty (variance) simultaneously. This approach allows them to model the aleatoric uncertainty inherent in the SR process and to leverage prior knowledge for regularization.\nLet \\(y_i\\) and \\(x_i\\) denote the low resolution and the respective high resolution image respectively. If \\(f(\\cdot)\\) denotes an arbitrary SISR network and aleatoric uncertainty \\(\\theta_i\\). The additive form of overall observation model can be written as:\n\\[\nx_i = f(y_i) + \\theta_i\n\\tag{1}\\]\nwhere \\(\\epsilon\\) represents the Laplace distribution with zero mean and unit variance.\nTraditional DL based models just focused on the mean, \\(f(y_i)\\) and discard the variance term \\(\\theta_i\\). For high level vision task it will not raise any issues. But this approach is not suitable for low-level vision tasks like SISR, where high-uncertainty pixels (e.g., texture and edge pixels) are visually more important and should be prioritized. This discrepancy motivates their approach of prioritizing pixels in low-level vision tasks.\nFor the \\((x_i,y_i)\\) pair, the likelihood function is defined as:\n\\[\np(x_i,\\theta_i|y_i)=\\dfrac{1}{2\\theta_i}\\text{exp}\\left(-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}\\right)\n\\tag{2}\\]\nWhere \\(f(y_i)\\) and \\(\\theta_i\\) denote the SR image and the uncertainty which are to be learned by a DL network respectively.\nThe log-likelihood function is written as:\n\\[\n\\ln(p(x_i,\\theta_i|y_i))=-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}-\\ln(\\theta_i)-\\ln 2\n\\tag{3}\\]\nTo address the numerical stability of the estimation \\(s=-\\ln (\\theta_1)\\) will be estimated from the log-likelihood of \\(N\\) samples defined by:\n\\[\n\\mathcal{L}_{EU}=\\frac{1}{N}\\sum\\limits_{i=1}^N\\text{exp}(-s_i)||x_i-f(y_i)||_1+s_i\n\\tag{4}\\]\nSo a MLE of Equation 3 is same as the minimization of Equation 4. \\(\\mathcal{L}_{EU}\\) is called the estimating uncertainty loss for the SR problem.\nThe authors observe that most pixels in an image have relatively low uncertainty, while only a few texture and edge pixels have high uncertainty. By imposing a sparsity prior, they prevent the network from predicting high uncertainty for all pixels, leading to a more accurate and meaningful uncertainty estimation. The Jeffrey’s prior, \\(p(\\theta_i)\\propto \\dfrac{1}{\\theta_i}\\) is used to encourage sparsity in the uncertainty map. Using the Bayer’s probability:\n\\[\np(x_i,\\theta_i|y_i)=p(x_i|y_i,\\theta_i)\\cdot p(\\theta_i)=\\dfrac{1}{2\\theta_i}\\text{exp}\\left(-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}\\right)\\cdot \\frac{1}{\\theta_i}=\\dfrac{1}{2\\theta_i^2}\\text{exp}\\left(-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}\\right)\n\\tag{5}\\]\nThe maximum likelihood estimate for logarithm of \\(\\theta_i=s\\) is the minimization of log likelihood of the joint distribution of Equation 5 on \\(N\\) samples.\nAuthors proposed this function as their new loss function as:\n\\[\n\\mathcal{L}_{ESU}=\\frac{1}{N}\\sum\\limits_{i=1}^N\\text{exp}(-s_i)||x_i-f(y_i)||_1+2s_i\n\\tag{6}\\]\nTo ensure stable performance in both high-level and low-lvel image processing applications, the authors proposed an adaptive loss function defined by:\n\\[\n\\mathcal{L}_{UDL}=\\frac{1}{N}\\sum\\limits_{i=1}^N\\\\hat{s_i}||x_i-f(y_i)||_1\n\\tag{7}\\]\nWhere \\(\\hat{s_i}=s_i-\\min{s_i}\\); \\(i=1,\\ldots , N\\) is a non-negative linear scaling function.\nTo prevent uncertainty value from degenerating into zeros, the result of uncertainty estimation network in the first step will be passed to the second step as the attention signal (\\(s =\\ln(\\theta)\\)). The two step flow diagram of the proposed UDL is shown in Figure 1.\n\n\n\n\n\n\nFigure 1: Block diagram of UDL implementation"
  },
  {
    "objectID": "PhD_Literature_survey.html#two-main-components-of-the-udl",
    "href": "PhD_Literature_survey.html#two-main-components-of-the-udl",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "Estimating Sparsity Uncertainty (ESU): This component estimates the pixel-wise uncertainty (variance) of the SR image. They use a Convolutional Neural Network (CNN) to predict the log variance, and regularize it using Jeffrey’s prior to promote sparsity in the uncertainty map. The loss used for this step is LESU.\nUncertainty-Driven Loss (LUDL): This is the adaptive weighted loss that guides the SISR network. It uses the uncertainty map estimated by ESU to assign larger weights to high-uncertainty pixels, effectively prioritizing them during training. The loss is computed using (Equation 7).\n\nThe method estimates a pixel-wise variance map (uncertainty) along with the SR image. It is assumed that the laplace distribution charateristics, can be captured with the variance map which is a latent variable. The authors use Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) to evaluate the performance of their proposed method. The experimental results demonstrate that the proposed UDL consistently outperforms traditional loss functions (MSE, L1) and other state-of-the-art SISR methods (including those that model uncertainty, like GRAM) in terms of PSNR and SSIM on several benchmark datasets."
  },
  {
    "objectID": "PhD_Literature_survey.html#key-contributions-of-this-work",
    "href": "PhD_Literature_survey.html#key-contributions-of-this-work",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "The main contribution of the loss function based approach are:\n\nA Bayesian estimation framework for SISR that simultaneously estimates the SR image and its uncertainty.\nA new uncertainty-driven loss (UDL) that prioritizes high-uncertainty pixels during training.\nA demonstration that UDL achieves better performance than traditional loss functions and other state-of-the-art methods without increasing computational cost during testing."
  },
  {
    "objectID": "PhD_Literature_survey.html#limitations-of-the-study",
    "href": "PhD_Literature_survey.html#limitations-of-the-study",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "The authors did not provide a thorough analysis of the computational cost during the training phase, focusing primarily on the testing phase.\nThe method relies on a two-step training process, which may be more complex to implement and tune than single-step training methods.\nThe performance improvements, while consistent, are relatively modest in some cases.\nThe choice of Jeffrey’s prior for regularizing the uncertainty map is somewhat heuristic and may not be optimal for all types of images."
  },
  {
    "objectID": "PhD_Literature_survey.html#future-work",
    "href": "PhD_Literature_survey.html#future-work",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "The authors suggested exploring a deep equilibrium model for SISR by iteratively alternating between estimating the uncertainty (variance) and the mean value.\nInvestigate alternative priors for regularizing the uncertainty map.\nExplore different network architectures for estimating uncertainty.\nDevelop end-to-end trainable UDL methods that do not require a two-step training process.\nApply the UDL framework to other low-level vision tasks.\nExplore perceptual metrics in the loss function."
  },
  {
    "objectID": "PhD_Literature_survey.html#review-summary",
    "href": "PhD_Literature_survey.html#review-summary",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "Single image super-resolution (SISR) aims to reconstruct high-resolution (HR) images from their low-resolution (LR) counterparts. Traditional loss functions, such as Mean Squared Error (MSE) or L1 loss, treat all pixels equally, disregarding the varying importance of textures and edges. Existing SISR methods often fail to adequately address this, motivating the need for spatially adaptive approaches Ning et al. (2021).\nTo overcome these limitations, authors proposed an uncertainty-driven loss (UDL) for SISR, prioritizing pixels with high uncertainty (e.g., textures and edges) during training. By casting SISR as a Bayesian estimation problem, their method simultaneously estimates the SR image (mean) and its uncertainty (variance). UDL incorporates an Estimating Sparsity Uncertainty (ESU) component regularized with Jeffrey’s prior, ensuring a more accurate uncertainty map. This map then guides the uncertainty-driven loss itself (LUDL), weighting high-uncertainty pixels more heavily.\nExperimental results demonstrated that the proposed UDL outperforms traditional loss functions and other SISR methods, achieving better Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) scores. Visual comparisons confirmed improved reconstruction of textures and edges. While promising, the authors note limitations regarding computational complexity during training and potential dataset biases. This work highlights the benefits of modeling uncertainty in SISR and provides a pathway for future research into adaptive loss functions for low-level vision tasks.\n\nNing, Q., Dong, W., Li, X., Wu, J., & Shi, G. (2021). Uncertainty-Driven Loss for Single Image Super-Resolution. 35th Conference on Neural Information Processing Systems (NeurIPS 2021)"
  },
  {
    "objectID": "PhD_Literature_survey.html#methodology-and-results",
    "href": "PhD_Literature_survey.html#methodology-and-results",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "Methodology and Results",
    "text": "Methodology and Results\nThe authors employed a Residual Encoder-Decoder Network (RED-Net) and trained it from scratch with various loss functions, including their proposed DDM and Feature and Frequency Based losses. They used an SR-SIM dataset of U2OS cells and the Berkeley Segmentation Dataset (BSD500) for evaluation. Performance was assessed using Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Normalized Root Mean Square Error (NRMSE).\nTheir key findings demonstrate that:\n\nThe proposed DDM and Feature and Frequency Based losses outperform traditional loss functions (MSE/L2, Mix Loss, VGG-based losses) on both SR-SIM and BSD datasets.\nVisual results support the quantitative findings, showing improved preservation of cellular structures and reduced artifacts."
  },
  {
    "objectID": "PhD_Literature_survey.html#limitations-and-future-directions",
    "href": "PhD_Literature_survey.html#limitations-and-future-directions",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "Limitations and Future Directions",
    "text": "Limitations and Future Directions\nShah et al. (2022) acknowledge limitations in their work, including:\n\nLack of quantitative comparison of computational complexity.\nEmpirical hyperparameter tuning with limited justification for the chosen values.\nRelatively small datasets.\nAbsence of comparison to other state-of-the-art SR-SIM denoising methods.\n\nBuilding on this work, future research could explore:\n\nAdaptive loss weighting strategies to dynamically adjust the influence of different loss components.\nAlternative frequency domain representations beyond the FFT (e.g., wavelets).\nThe use of learned loss functions trained with CNNs.\nApplication of the proposed losses to other microscopy modalities.\n\n\nShah, Z.H., Müller, M., Hammer, B., Huser, T. and Schenck, W., 2022, July. Impact of different loss functions on denoising of microscopic images. In 2022 International Joint Conference on Neural Networks (IJCNN) (pp. 1-10). IEEE."
  },
  {
    "objectID": "PhD_Literature_survey.html#summary",
    "href": "PhD_Literature_survey.html#summary",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "Summary",
    "text": "Summary\nHuang et al. (2020) addressed the challenge of enhancing image quality in deep learning-based inverse scattering (DL-IS) methods, noting that traditional pixel-wise loss functions like Mean Squared Error (MSE) fail to capture crucial structural information. To overcome this limitation, the authors proposed a novel approach incorporating a Structural Similarity (SSIM) loss function into the training process. Their method leverages a U-Net Convolutional Neural Network (CNN) to map a rough initial image, obtained via the backpropagation (BP) method, to a high-resolution reconstruction.\nThe core of their approach lies in the hybrid loss function, defined as:\n\\[\nL_{full}(\\hat{y}, y) = L_{mse}(\\hat{y}, y) + \\alpha L_{ssim} (\\hat{y}, y)\n\\tag{12}\\]\nWhere \\(L_{mse}\\) is defined as:\n\\[\nL_{mse}=\\dfrac{1}{W\\times H}\\sum\\limits_{i=1}^W\\sum\\limits_{j=1}^H\\left(\\hat{y}_{i,j}-y_{i,j}\\right)^2\n\\tag{13}\\]\nand the SSIM loss is:\n\\[\n\\begin{align*}\nL_{ssim}&=1-SSIM(\\hat{y},y)\\\\\n        &=1-\\dfrac{(2\\mu_{y\\hat{y}}\\mu_y+C_1)(2\\sigma_{\\hat{y}y}+C_2)}{(\\mu^2_{\\hat{y}}+\\mu^2_y+C_1)(\\sigma^2_{\\hat{y}}+\\sigma^2_y+C_2)}\n\\end{align*}\n\\tag{14}\\]\n\\(C_1=(K_1\\mathcal{L})^2\\), \\(C_2=(K_2\\mathcal{L})^2\\) are two small constants used to keep the denominator non-zero and \\(K_1\\) and \\(K_2\\) are hyper parameters. \\(\\mathcal{L}\\) is the dynamic range of pixel values of the target variable \\(y\\). (In this paper authors use \\(K_1=0.01, K_2=0.03\\)).\nIn their work, the authors applied the SSIM loss on patches of images. The full size image is divided into \\(N_p\\) patches with each patch occupying \\(M\\times M\\) pixels. So the loss function defined for the full image is given by:\n\\[\nL_{\\text{full}}=\\sum\\limits_{j=1}^{N_p} L_{mse}(\\hat{y}_j,y_j)+\\alpha L_{\\text{ssim}}(\\hat{y}_j,y_j)\n\\tag{15}\\]\nNumerical tests using both synthetic (MNIST digits) and experimental (“FoamDielExt” profile) data demonstrated the effectiveness of their method. The results showed that incorporating the Structural Similarity (SSIM) loss improved imaging quality compared to using Mean Squared Error (MSE) alone and offered a better performance than traditional methods. For experimental data, the method showed very promising results but was also outperformed by traditional optimization in some cases.\nHuang et al. (2020) demonstrated that the developed technique improved reconstruction quality and helped to alleviate the artifacts, but they acknowledge that their work is preliminary and focuses only on relatively basic geometries and material properties. Nonetheless, this work illustrates the value of perceptual loss functions and gives insight on how to enhance Deep Learning Based Inverse Scattering (DL-IS) techniques.\n\nHuang, Y., Song, R., Xu, K., Ye, X., Li, C. and Chen, X., 2020. Deep learning-based inverse scattering with structural similarity loss functions. IEEE Sensors Journal, 21(4), pp.4900-4907."
  },
  {
    "objectID": "daily_entry.html",
    "href": "daily_entry.html",
    "title": "End of First Semester - November 23, 2023",
    "section": "",
    "text": "24MA604 Computational Mathematics for Data Science\n24DS601 Machine Learning\n24RM801 Research Methodology for Engineering\n\n\n\nIt has been a challenging yet enriching semester, where I gained a strong foundation in Computational Mathematics, Machine Learning, and Research Methodology. Some key takeaways include:\n\nComputational Mathematics: Developed a deeper understanding of mathematical concepts crucial for data science, including stochastic models and optimization techniques.\nMachine Learning: Learned about various machine learning algorithms, their applications, and the importance of data preprocessing.\nResearch Methodology: Gained insights into the research process, including methodology, paper writing, and presentation skills.\n\n\n\n\nThe semester ended with course viva-voce, project presentations, and final exams. I presented my work on Computational Linear Algebra, where I demonstrated the progress and insights from the semester.\n\nLooking forward to continuing the journey in the next semester, with new challenges and opportunities for growth."
  },
  {
    "objectID": "daily_entry.html#courses-completed",
    "href": "daily_entry.html#courses-completed",
    "title": "End of First Semester - November 23, 2023",
    "section": "",
    "text": "24MA604 Computational Mathematics for Data Science\n24DS601 Machine Learning\n24RM801 Research Methodology for Engineering\n\n\n\nIt has been a challenging yet enriching semester, where I gained a strong foundation in Computational Mathematics, Machine Learning, and Research Methodology. Some key takeaways include:\n\nComputational Mathematics: Developed a deeper understanding of mathematical concepts crucial for data science, including stochastic models and optimization techniques.\nMachine Learning: Learned about various machine learning algorithms, their applications, and the importance of data preprocessing.\nResearch Methodology: Gained insights into the research process, including methodology, paper writing, and presentation skills.\n\n\n\n\nThe semester ended with course viva-voce, project presentations, and final exams. I presented my work on Computational Linear Algebra, where I demonstrated the progress and insights from the semester.\n\nLooking forward to continuing the journey in the next semester, with new challenges and opportunities for growth."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Coursework Diary",
    "section": "",
    "text": "Welcome to my coursework diary. Here, I document my daily research activities, thoughts, and progress related to my research in Computational Engineering and Mathematics.\n\n\n\nKeep track of daily research activities.\nShare insights and reflections from my work.\nStore resources and references for future use.\n\n\n\n\n\nDate: r Sys.Date()\nResearch Focus: Today, I worked on X and Y.\n\nFor more details, please explore the different sections of this site."
  },
  {
    "objectID": "index.html#objectives",
    "href": "index.html#objectives",
    "title": "Welcome to My Coursework Diary",
    "section": "",
    "text": "Keep track of daily research activities.\nShare insights and reflections from my work.\nStore resources and references for future use."
  },
  {
    "objectID": "index.html#recent-updates",
    "href": "index.html#recent-updates",
    "title": "Welcome to My Coursework Diary",
    "section": "",
    "text": "Date: r Sys.Date()\nResearch Focus: Today, I worked on X and Y.\n\nFor more details, please explore the different sections of this site."
  }
]