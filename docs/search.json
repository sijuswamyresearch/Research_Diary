[
  {
    "objectID": "PhD_Literature_survey.html",
    "href": "PhD_Literature_survey.html",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "The authors argued that traditional Mean Squared Error (MSE) or L1 loss functions used in DL based super resolution models treat every pixel equally, regardless of its importance to visual perception. This is problematic because texture and edge areas carry more vital visual information than smooth areas, and MSE/L1 don’t account for this spatial variation. The equal weightage is non-optimal because it does not adaptive to the local image features which is an open research problem. Existing deep learning-based Single Image Super-Resolution (SISR) methods primarily focus on increasing network depth and complexity, or introducing attention mechanisms, while still relying on MSE or L1 loss. The authors contend that these methods do not explicitly address how to prioritize pixels containing important visual information in a principled and adaptive manner during the training process.\n\n\n\nIn the context of SISR, authors coined a new term “uncertainty” refers to the inherent ambiguity in reconstructing a high-resolution (HR) image from a low-resolution (LR) counterpart. They used uncertainty as a measure of difficulty in accurate image reconstruction.\nThe authors propose an adaptive weighted loss, uncertainty driven loss (UDL), that prioritizes texture and edge pixels with high uncertainty during training. Unlike traditional methods, UDL assigns larger weights to these pixels, forcing the network to focus on accurately reconstructing them. This addresses the limitations of MSE/L1 by explicitly accounting for the spatial variation in importance across different image regions.\nThere are two classes of uncertainty in Bayesian modeling: aleatoric uncertainty capturing noise inherent in observation data and epistemic uncertainty accounting for uncertainty of model about its predictions. The authors formulated SISR as a Bayesian estimation problem using the aleatoric uncertainty where the goal is to estimate not only the Super Resolved (SR) image (mean) but also its uncertainty (variance) simultaneously. This approach allows them to model the aleatoric uncertainty inherent in the SR process and to leverage prior knowledge for regularization.\nLet \\(y_i\\) and \\(x_i\\) denote the low resolution and the respective high resolution image respectively. If \\(f(\\cdot)\\) denotes an arbitrary SISR network and aleatoric uncertainty \\(\\theta_i\\). The additive form of overall observation model can be written as:\n\\[\nx_i = f(y_i) + \\theta_i\n\\tag{1}\\]\nwhere \\(\\epsilon\\) represents the Laplace distribution with zero mean and unit variance.\nTraditional DL based models just focused on the mean, \\(f(y_i)\\) and discard the variance term \\(\\theta_i\\). For high level vision task it will not raise any issues. But this approach is not suitable for low-level vision tasks like SISR, where high-uncertainty pixels (e.g., texture and edge pixels) are visually more important and should be prioritized. This discrepancy motivates their approach of prioritizing pixels in low-level vision tasks.\nFor the \\((x_i,y_i)\\) pair, the likelihood function is defined as:\n\\[\np(x_i,\\theta_i|y_i)=\\dfrac{1}{2\\theta_i}\\text{exp}\\left(-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}\\right)\n\\tag{2}\\]\nWhere \\(f(y_i)\\) and \\(\\theta_i\\) denote the SR image and the uncertainty which are to be learned by a DL network respectively.\nThe log-likelihood function is written as:\n\\[\n\\ln(p(x_i,\\theta_i|y_i))=-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}-\\ln(\\theta_i)-\\ln 2\n\\tag{3}\\]\nTo address the numerical stability of the estimation \\(s=-\\ln (\\theta_1)\\) will be estimated from the log-likelihood of \\(N\\) samples defined by:\n\\[\n\\mathcal{L}_{EU}=\\frac{1}{N}\\sum\\limits_{i=1}^N\\text{exp}(-s_i)||x_i-f(y_i)||_1+s_i\n\\tag{4}\\]\nSo a MLE of Equation 3 is same as the minimization of Equation 4. \\(\\mathcal{L}_{EU}\\) is called the estimating uncertainty loss for the SR problem.\nThe authors observe that most pixels in an image have relatively low uncertainty, while only a few texture and edge pixels have high uncertainty. By imposing a sparsity prior, they prevent the network from predicting high uncertainty for all pixels, leading to a more accurate and meaningful uncertainty estimation. The Jeffrey’s prior, \\(p(\\theta_i)\\propto \\dfrac{1}{\\theta_i}\\) is used to encourage sparsity in the uncertainty map. Using the Bayer’s probability:\n\\[\np(x_i,\\theta_i|y_i)=p(x_i|y_i,\\theta_i)\\cdot p(\\theta_i)=\\dfrac{1}{2\\theta_i}\\text{exp}\\left(-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}\\right)\\cdot \\frac{1}{\\theta_i}=\\dfrac{1}{2\\theta_i^2}\\text{exp}\\left(-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}\\right)\n\\tag{5}\\]\nThe maximum likelihood estimate for logarithm of \\(\\theta_i=s\\) is the minimization of log likelihood of the joint distribution of Equation 5 on \\(N\\) samples.\nAuthors proposed this function as their new loss function as:\n\\[\n\\mathcal{L}_{ESU}=\\frac{1}{N}\\sum\\limits_{i=1}^N\\text{exp}(-s_i)||x_i-f(y_i)||_1+2s_i\n\\tag{6}\\]\nTo ensure stable performance in both high-level and low-lvel image processing applications, the authors proposed an adaptive loss function defined by:\n\\[\n\\mathcal{L}_{UDL}=\\frac{1}{N}\\sum\\limits_{i=1}^N\\\\hat{s_i}||x_i-f(y_i)||_1\n\\tag{7}\\]\nWhere \\(\\hat{s_i}=s_i-\\min{s_i}\\); \\(i=1,\\ldots , N\\) is a non-negative linear scaling function.\nTo prevent uncertainty value from degenerating into zeros, the result of uncertainty estimation network in the first step will be passed to the second step as the attention signal (\\(s =\\ln(\\theta)\\)). The two step flow diagram of the proposed UDL is shown in Figure 1.\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\nEstimating Sparsity Uncertainty (ESU): This component estimates the pixel-wise uncertainty (variance) of the SR image. They use a Convolutional Neural Network (CNN) to predict the log variance, and regularize it using Jeffrey’s prior to promote sparsity in the uncertainty map. The loss used for this step is LESU.\nUncertainty-Driven Loss (LUDL): This is the adaptive weighted loss that guides the SISR network. It uses the uncertainty map estimated by ESU to assign larger weights to high-uncertainty pixels, effectively prioritizing them during training. The loss is computed using (Equation 7).\n\nThe method estimates a pixel-wise variance map (uncertainty) along with the SR image. It is assumed that the laplace distribution charateristics, can be captured with the variance map which is a latent variable. The authors use Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) to evaluate the performance of their proposed method. The experimental results demonstrate that the proposed UDL consistently outperforms traditional loss functions (MSE, L1) and other state-of-the-art SISR methods (including those that model uncertainty, like GRAM) in terms of PSNR and SSIM on several benchmark datasets.\n\n\n\nThe main contribution of the loss function based approach are:\n\nA Bayesian estimation framework for SISR that simultaneously estimates the SR image and its uncertainty.\nA new uncertainty-driven loss (UDL) that prioritizes high-uncertainty pixels during training.\nA demonstration that UDL achieves better performance than traditional loss functions and other state-of-the-art methods without increasing computational cost during testing.\n\n\n\n\n\nThe authors did not provide a thorough analysis of the computational cost during the training phase, focusing primarily on the testing phase.\nThe method relies on a two-step training process, which may be more complex to implement and tune than single-step training methods.\nThe performance improvements, while consistent, are relatively modest in some cases.\nThe choice of Jeffrey’s prior for regularizing the uncertainty map is somewhat heuristic and may not be optimal for all types of images.\n\n\n\n\n\nThe authors suggested exploring a deep equilibrium model for SISR by iteratively alternating between estimating the uncertainty (variance) and the mean value.\nInvestigate alternative priors for regularizing the uncertainty map.\nExplore different network architectures for estimating uncertainty.\nDevelop end-to-end trainable UDL methods that do not require a two-step training process.\nApply the UDL framework to other low-level vision tasks.\nExplore perceptual metrics in the loss function.\n\n\n\n\nSingle image super-resolution (SISR) aims to reconstruct high-resolution (HR) images from their low-resolution (LR) counterparts. Traditional loss functions, such as Mean Squared Error (MSE) or L1 loss, treat all pixels equally, disregarding the varying importance of textures and edges. Existing SISR methods often fail to adequately address this, motivating the need for spatially adaptive approaches Ning et al. (2021).\nTo overcome these limitations, authors proposed an uncertainty-driven loss (UDL) for SISR, prioritizing pixels with high uncertainty (e.g., textures and edges) during training. By casting SISR as a Bayesian estimation problem, their method simultaneously estimates the SR image (mean) and its uncertainty (variance). UDL incorporates an Estimating Sparsity Uncertainty (ESU) component regularized with Jeffrey’s prior, ensuring a more accurate uncertainty map. This map then guides the uncertainty-driven loss itself (LUDL), weighting high-uncertainty pixels more heavily.\nExperimental results demonstrated that the proposed UDL outperforms traditional loss functions and other SISR methods, achieving better Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) scores. Visual comparisons confirmed improved reconstruction of textures and edges. While promising, the authors note limitations regarding computational complexity during training and potential dataset biases. This work highlights the benefits of modeling uncertainty in SISR and provides a pathway for future research into adaptive loss functions for low-level vision tasks.\n\nNing, Q., Dong, W., Li, X., Wu, J., & Shi, G. (2021). Uncertainty-Driven Loss for Single Image Super-Resolution. 35th Conference on Neural Information Processing Systems (NeurIPS 2021)"
  },
  {
    "objectID": "PhD_Literature_survey.html#research-gap-identified-in-the-paper",
    "href": "PhD_Literature_survey.html#research-gap-identified-in-the-paper",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "The authors argued that traditional Mean Squared Error (MSE) or L1 loss functions used in DL based super resolution models treat every pixel equally, regardless of its importance to visual perception. This is problematic because texture and edge areas carry more vital visual information than smooth areas, and MSE/L1 don’t account for this spatial variation. The equal weightage is non-optimal because it does not adaptive to the local image features which is an open research problem. Existing deep learning-based Single Image Super-Resolution (SISR) methods primarily focus on increasing network depth and complexity, or introducing attention mechanisms, while still relying on MSE or L1 loss. The authors contend that these methods do not explicitly address how to prioritize pixels containing important visual information in a principled and adaptive manner during the training process."
  },
  {
    "objectID": "PhD_Literature_survey.html#proposed-approach",
    "href": "PhD_Literature_survey.html#proposed-approach",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "In the context of SISR, authors coined a new term “uncertainty” refers to the inherent ambiguity in reconstructing a high-resolution (HR) image from a low-resolution (LR) counterpart. They used uncertainty as a measure of difficulty in accurate image reconstruction.\nThe authors propose an adaptive weighted loss, uncertainty driven loss (UDL), that prioritizes texture and edge pixels with high uncertainty during training. Unlike traditional methods, UDL assigns larger weights to these pixels, forcing the network to focus on accurately reconstructing them. This addresses the limitations of MSE/L1 by explicitly accounting for the spatial variation in importance across different image regions.\nThere are two classes of uncertainty in Bayesian modeling: aleatoric uncertainty capturing noise inherent in observation data and epistemic uncertainty accounting for uncertainty of model about its predictions. The authors formulated SISR as a Bayesian estimation problem using the aleatoric uncertainty where the goal is to estimate not only the Super Resolved (SR) image (mean) but also its uncertainty (variance) simultaneously. This approach allows them to model the aleatoric uncertainty inherent in the SR process and to leverage prior knowledge for regularization.\nLet \\(y_i\\) and \\(x_i\\) denote the low resolution and the respective high resolution image respectively. If \\(f(\\cdot)\\) denotes an arbitrary SISR network and aleatoric uncertainty \\(\\theta_i\\). The additive form of overall observation model can be written as:\n\\[\nx_i = f(y_i) + \\theta_i\n\\tag{1}\\]\nwhere \\(\\epsilon\\) represents the Laplace distribution with zero mean and unit variance.\nTraditional DL based models just focused on the mean, \\(f(y_i)\\) and discard the variance term \\(\\theta_i\\). For high level vision task it will not raise any issues. But this approach is not suitable for low-level vision tasks like SISR, where high-uncertainty pixels (e.g., texture and edge pixels) are visually more important and should be prioritized. This discrepancy motivates their approach of prioritizing pixels in low-level vision tasks.\nFor the \\((x_i,y_i)\\) pair, the likelihood function is defined as:\n\\[\np(x_i,\\theta_i|y_i)=\\dfrac{1}{2\\theta_i}\\text{exp}\\left(-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}\\right)\n\\tag{2}\\]\nWhere \\(f(y_i)\\) and \\(\\theta_i\\) denote the SR image and the uncertainty which are to be learned by a DL network respectively.\nThe log-likelihood function is written as:\n\\[\n\\ln(p(x_i,\\theta_i|y_i))=-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}-\\ln(\\theta_i)-\\ln 2\n\\tag{3}\\]\nTo address the numerical stability of the estimation \\(s=-\\ln (\\theta_1)\\) will be estimated from the log-likelihood of \\(N\\) samples defined by:\n\\[\n\\mathcal{L}_{EU}=\\frac{1}{N}\\sum\\limits_{i=1}^N\\text{exp}(-s_i)||x_i-f(y_i)||_1+s_i\n\\tag{4}\\]\nSo a MLE of Equation 3 is same as the minimization of Equation 4. \\(\\mathcal{L}_{EU}\\) is called the estimating uncertainty loss for the SR problem.\nThe authors observe that most pixels in an image have relatively low uncertainty, while only a few texture and edge pixels have high uncertainty. By imposing a sparsity prior, they prevent the network from predicting high uncertainty for all pixels, leading to a more accurate and meaningful uncertainty estimation. The Jeffrey’s prior, \\(p(\\theta_i)\\propto \\dfrac{1}{\\theta_i}\\) is used to encourage sparsity in the uncertainty map. Using the Bayer’s probability:\n\\[\np(x_i,\\theta_i|y_i)=p(x_i|y_i,\\theta_i)\\cdot p(\\theta_i)=\\dfrac{1}{2\\theta_i}\\text{exp}\\left(-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}\\right)\\cdot \\frac{1}{\\theta_i}=\\dfrac{1}{2\\theta_i^2}\\text{exp}\\left(-\\dfrac{||x_i-f(y_i)||_1}{\\theta_i}\\right)\n\\tag{5}\\]\nThe maximum likelihood estimate for logarithm of \\(\\theta_i=s\\) is the minimization of log likelihood of the joint distribution of Equation 5 on \\(N\\) samples.\nAuthors proposed this function as their new loss function as:\n\\[\n\\mathcal{L}_{ESU}=\\frac{1}{N}\\sum\\limits_{i=1}^N\\text{exp}(-s_i)||x_i-f(y_i)||_1+2s_i\n\\tag{6}\\]\nTo ensure stable performance in both high-level and low-lvel image processing applications, the authors proposed an adaptive loss function defined by:\n\\[\n\\mathcal{L}_{UDL}=\\frac{1}{N}\\sum\\limits_{i=1}^N\\\\hat{s_i}||x_i-f(y_i)||_1\n\\tag{7}\\]\nWhere \\(\\hat{s_i}=s_i-\\min{s_i}\\); \\(i=1,\\ldots , N\\) is a non-negative linear scaling function.\nTo prevent uncertainty value from degenerating into zeros, the result of uncertainty estimation network in the first step will be passed to the second step as the attention signal (\\(s =\\ln(\\theta)\\)). The two step flow diagram of the proposed UDL is shown in Figure 1.\n\n\n\n\n\n\nFigure 1"
  },
  {
    "objectID": "PhD_Literature_survey.html#review-summary",
    "href": "PhD_Literature_survey.html#review-summary",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "Single image super-resolution (SISR) aims to reconstruct high-resolution (HR) images from their low-resolution (LR) counterparts. Traditional loss functions, such as Mean Squared Error (MSE) or L1 loss, treat all pixels equally, disregarding the varying importance of textures and edges. Existing SISR methods often fail to adequately address this, motivating the need for spatially adaptive approaches Ning et al. (2021).\nTo overcome these limitations, authors proposed an uncertainty-driven loss (UDL) for SISR, prioritizing pixels with high uncertainty (e.g., textures and edges) during training. By casting SISR as a Bayesian estimation problem, their method simultaneously estimates the SR image (mean) and its uncertainty (variance). UDL incorporates an Estimating Sparsity Uncertainty (ESU) component regularized with Jeffrey’s prior, ensuring a more accurate uncertainty map. This map then guides the uncertainty-driven loss itself (LUDL), weighting high-uncertainty pixels more heavily.\nExperimental results demonstrated that the proposed UDL outperforms traditional loss functions and other SISR methods, achieving better Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) scores. Visual comparisons confirmed improved reconstruction of textures and edges. While promising, the authors note limitations regarding computational complexity during training and potential dataset biases. This work highlights the benefits of modeling uncertainty in SISR and provides a pathway for future research into adaptive loss functions for low-level vision tasks.\n\nNing, Q., Dong, W., Li, X., Wu, J., & Shi, G. (2021). Uncertainty-Driven Loss for Single Image Super-Resolution. 35th Conference on Neural Information Processing Systems (NeurIPS 2021)"
  },
  {
    "objectID": "daily_entry.html",
    "href": "daily_entry.html",
    "title": "End of First Semester - November 23, 2023",
    "section": "",
    "text": "24MA604 Computational Mathematics for Data Science\n24DS601 Machine Learning\n24RM801 Research Methodology for Engineering\n\n\n\nIt has been a challenging yet enriching semester, where I gained a strong foundation in Computational Mathematics, Machine Learning, and Research Methodology. Some key takeaways include:\n\nComputational Mathematics: Developed a deeper understanding of mathematical concepts crucial for data science, including stochastic models and optimization techniques.\nMachine Learning: Learned about various machine learning algorithms, their applications, and the importance of data preprocessing.\nResearch Methodology: Gained insights into the research process, including methodology, paper writing, and presentation skills.\n\n\n\n\nThe semester ended with course viva-voce, project presentations, and final exams. I presented my work on Computational Linear Algebra, where I demonstrated the progress and insights from the semester.\n\nLooking forward to continuing the journey in the next semester, with new challenges and opportunities for growth."
  },
  {
    "objectID": "daily_entry.html#courses-completed",
    "href": "daily_entry.html#courses-completed",
    "title": "End of First Semester - November 23, 2023",
    "section": "",
    "text": "24MA604 Computational Mathematics for Data Science\n24DS601 Machine Learning\n24RM801 Research Methodology for Engineering\n\n\n\nIt has been a challenging yet enriching semester, where I gained a strong foundation in Computational Mathematics, Machine Learning, and Research Methodology. Some key takeaways include:\n\nComputational Mathematics: Developed a deeper understanding of mathematical concepts crucial for data science, including stochastic models and optimization techniques.\nMachine Learning: Learned about various machine learning algorithms, their applications, and the importance of data preprocessing.\nResearch Methodology: Gained insights into the research process, including methodology, paper writing, and presentation skills.\n\n\n\n\nThe semester ended with course viva-voce, project presentations, and final exams. I presented my work on Computational Linear Algebra, where I demonstrated the progress and insights from the semester.\n\nLooking forward to continuing the journey in the next semester, with new challenges and opportunities for growth."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Coursework Diary",
    "section": "",
    "text": "Welcome to my coursework diary. Here, I document my daily research activities, thoughts, and progress related to my research in Computational Engineering and Mathematics.\n\n\n\nKeep track of daily research activities.\nShare insights and reflections from my work.\nStore resources and references for future use.\n\n\n\n\n\nDate: r Sys.Date()\nResearch Focus: Today, I worked on X and Y.\n\nFor more details, please explore the different sections of this site."
  },
  {
    "objectID": "index.html#objectives",
    "href": "index.html#objectives",
    "title": "Welcome to My Coursework Diary",
    "section": "",
    "text": "Keep track of daily research activities.\nShare insights and reflections from my work.\nStore resources and references for future use."
  },
  {
    "objectID": "index.html#recent-updates",
    "href": "index.html#recent-updates",
    "title": "Welcome to My Coursework Diary",
    "section": "",
    "text": "Date: r Sys.Date()\nResearch Focus: Today, I worked on X and Y.\n\nFor more details, please explore the different sections of this site."
  },
  {
    "objectID": "PhD_Literature_survey.html#two-main-components-of-the-udl",
    "href": "PhD_Literature_survey.html#two-main-components-of-the-udl",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "Estimating Sparsity Uncertainty (ESU): This component estimates the pixel-wise uncertainty (variance) of the SR image. They use a Convolutional Neural Network (CNN) to predict the log variance, and regularize it using Jeffrey’s prior to promote sparsity in the uncertainty map. The loss used for this step is LESU.\nUncertainty-Driven Loss (LUDL): This is the adaptive weighted loss that guides the SISR network. It uses the uncertainty map estimated by ESU to assign larger weights to high-uncertainty pixels, effectively prioritizing them during training. The loss is computed using (Equation 7).\n\nThe method estimates a pixel-wise variance map (uncertainty) along with the SR image. It is assumed that the laplace distribution charateristics, can be captured with the variance map which is a latent variable. The authors use Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) to evaluate the performance of their proposed method. The experimental results demonstrate that the proposed UDL consistently outperforms traditional loss functions (MSE, L1) and other state-of-the-art SISR methods (including those that model uncertainty, like GRAM) in terms of PSNR and SSIM on several benchmark datasets."
  },
  {
    "objectID": "PhD_Literature_survey.html#key-contributions-of-this-work",
    "href": "PhD_Literature_survey.html#key-contributions-of-this-work",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "The main contribution of the loss function based approach are:\n\nA Bayesian estimation framework for SISR that simultaneously estimates the SR image and its uncertainty.\nA new uncertainty-driven loss (UDL) that prioritizes high-uncertainty pixels during training.\nA demonstration that UDL achieves better performance than traditional loss functions and other state-of-the-art methods without increasing computational cost during testing."
  },
  {
    "objectID": "PhD_Literature_survey.html#limitations-of-the-study",
    "href": "PhD_Literature_survey.html#limitations-of-the-study",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "The authors did not provide a thorough analysis of the computational cost during the training phase, focusing primarily on the testing phase.\nThe method relies on a two-step training process, which may be more complex to implement and tune than single-step training methods.\nThe performance improvements, while consistent, are relatively modest in some cases.\nThe choice of Jeffrey’s prior for regularizing the uncertainty map is somewhat heuristic and may not be optimal for all types of images."
  },
  {
    "objectID": "PhD_Literature_survey.html#future-work",
    "href": "PhD_Literature_survey.html#future-work",
    "title": "Review of Literature in Core Research Area - February 25, 2025",
    "section": "",
    "text": "The authors suggested exploring a deep equilibrium model for SISR by iteratively alternating between estimating the uncertainty (variance) and the mean value.\nInvestigate alternative priors for regularizing the uncertainty map.\nExplore different network architectures for estimating uncertainty.\nDevelop end-to-end trainable UDL methods that do not require a two-step training process.\nApply the UDL framework to other low-level vision tasks.\nExplore perceptual metrics in the loss function."
  }
]